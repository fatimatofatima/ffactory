#!/usr/bin/env bash
set -Eeuo pipefail

log(){ echo "ðŸŸ¢ $*"; }
warn(){ echo "ðŸŸ¡ $*" >&2; }
die(){ echo "ðŸ”´ $*" >&2; exit 1; }

FF="/opt/ffactory"
APPS="$FF/apps"
STACK="$FF/stack"
APP_DIR="$APPS/asr-engine"
PROJECT=${COMPOSE_PROJECT_NAME:-ffactory}

[ -d "$APP_DIR" ] || die "Ù…Ø³Ø§Ø± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ $APP_DIR ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯."

# -----------------------------------------------------
# 1. ØªØ­Ø¯ÙŠØ« Dockerfile (Ø¥Ø¶Ø§ÙØ© ØªØ¨Ø¹ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø­ØªÙ…ÙŠØ©)
# -----------------------------------------------------
log "1/4. ØªØ­Ø¯ÙŠØ« Dockerfile: Ø¥Ø¶Ø§ÙØ© FFmpeg Ùˆ Git (Ø¶Ø±ÙˆØ±ÙŠØ§Ù† Ù„Ù„ØµÙˆØªÙŠØ§Øª ÙˆØ§Ù„ØªØ­Ù…ÙŠÙ„)..."
# Ù†Ø³ØªØ®Ø¯Ù… sed Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¨Ø¹Ø¯ Ø³Ø·Ø± FROM ÙˆÙ‚Ø¨Ù„ Ø£ÙŠ Ø´ÙŠØ¡ Ø¢Ø®Ø±
sed -i '/^FROM/a RUN apt-get update && apt-get install -y ffmpeg git libsndfile1 && rm -rf /var/lib/apt/lists/* \
    \n# FFIX: ØªØ«Ø¨ÙŠØª ØªØ¨Ø¹ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ù„Ù€ PyAnnote/Whisper' "$APP_DIR/Dockerfile"

# -----------------------------------------------------
# 2. ØªØ­Ø¯ÙŠØ« Ù…ØªØ·Ù„Ø¨Ø§Øª Python
# -----------------------------------------------------
log "2/4. ØªØ­Ø¯ÙŠØ« requirements.txt (Faster-Whisper + PyAnnote)..."
cat > "$APP_DIR/requirements.txt" << 'REQ_ASR'
fastapi>=0.104.0
uvicorn>=0.24.0
# Ù…Ø­Ø±Ùƒ ØªÙØ±ÙŠØº ÙØ§Ø¦Ù‚ Ø§Ù„Ø³Ø±Ø¹Ø©
faster-whisper>=10.3.0 
# Ù„ØªÙ…ÙŠÙŠØ² Ø§Ù„Ù…ØªØ­Ø¯Ø«ÙŠÙ† (ÙŠØªØ·Ù„Ø¨ ØªÙˆÙƒÙ† HF)
pyannote.audio>=3.1.1 
librosa>=0.10.1
# Ù„Ø£Ø¬Ù„ Pytorch - Ù†Ø¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø£Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ØªÙˆÙØ±Ù‡ Ø£Ùˆ ÙŠØªÙ… Ø¬Ù„Ø¨Ù‡ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
REQ_ASR

# -----------------------------------------------------
# 3. ÙƒØªØ§Ø¨Ø© ÙƒÙˆØ¯ FastAPI Ø§Ù„Ù‚ÙˆÙŠ
# -----------------------------------------------------
log "3/4. ÙƒØªØ§Ø¨Ø© ÙƒÙˆØ¯ ASR Engine Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ (FastAPI Ù…Ø¹ Whisper)..."

cat > "$APP_DIR/main.py" << 'PYTHON_ASR'
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import uvicorn
import asyncio
import os
import requests
import io

# ØªØ¨Ø¹ÙŠØ§Øª Ù…Ø¹Ù‚Ø¯Ø©
try:
    from faster_whisper import WhisperModel
    from pyannote.audio import Pipeline
    import torch
except ImportError as e:
    # Ø³ÙŠØªÙ… Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ù‡Ø°Ø§ Ø§Ù„ÙØ´Ù„ ÙƒÙˆØ¶Ø¹ "Deactivated"
    WHISPER_MODEL = None
    DIARIZATION_PIPELINE = None
    print(f"[ASR] ðŸ”´ ÙØ´Ù„ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…ÙƒØªØ¨Ø§Øª ASR: {e}. Ø§Ù„Ø¹Ù…Ù„ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø§Ø³ØªØ¹Ø¯Ø§Ø¯.")

# FFIX: ØªÙˆÙƒÙ† Hugging Face Ù„Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ù†Ù…Ø§Ø°Ø¬ PyAnnote
HF_TOKEN = os.environ.get("HUGGINGFACE_TOKEN", "MISSING_TOKEN")

class TranscriptionRequest(BaseModel):
    # Ù†Ø·Ù„Ø¨ URL Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø­Ù„ÙŠ Ù„ÙŠØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ MinIO Ø£Ùˆ Ø£ÙŠ Ù…ØµØ¯Ø± Ø®Ø§Ø±Ø¬ÙŠ
    audio_url: str 
    language: str = "ar"
    model_size: str = "medium" 

app = FastAPI(title="ASR Engine - Faster Whisper & Diarization")
WHISPER_MODEL = None
DIARIZATION_PIPELINE = None

def log(msg):
    print(f"[ASR] {msg}", flush=True)

@app.on_event("startup")
async def startup_event():
    global WHISPER_MODEL, DIARIZATION_PIPELINE
    log("Ø¨Ø¯Ø¡ ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ ASR...")

    # 1. ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Whisper
    try:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        log("ðŸŸ¢ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Whisper Ø¹Ù„Ù‰: " + device)
        WHISPER_MODEL = WhisperModel("medium", device=device, compute_type="int8")
    except Exception as e:
        log(f"ðŸ”´ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Whisper: {e}")

    # 2. ØªØ­Ù…ÙŠÙ„ PyAnnote Pipeline
    if HF_TOKEN != "MISSING_TOKEN":
        try:
            log("ðŸŸ¢ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Diarization (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªÙˆÙƒÙ†).")
            # PyAnnote/speaker-diarization-3.1
            DIARIZATION_PIPELINE = Pipeline.from_pretrained(
                "pyannote/speaker-diarization-3.1", use_auth_token=HF_TOKEN
            )
            if torch.cuda.is_available():
                DIARIZATION_PIPELINE.to(torch.device("cuda"))
        except Exception as e:
            log(f"ðŸ”´ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ PyAnnote: {e}")
            DIARIZATION_PIPELINE = None
    else:
        log("ðŸŸ¡ PyAnnote Ù…Ø¹Ø·Ù„. ÙŠØ±Ø¬Ù‰ ØªÙˆÙÙŠØ± HUGGINGFACE_TOKEN ÙƒÙ…ØªØºÙŠØ± Ø¨ÙŠØ¦Ø©.")


@app.get("/health")
async def health():
    return {
        "status": "healthy",
        "service": "asr-engine",
        "whisper_status": "READY" if WHISPER_MODEL else "FAILED/PENDING",
        "diarization_status": "READY" if DIARIZATION_PIPELINE else "DISABLED"
    }

@app.post("/transcribe")
async def transcribe_audio(req: TranscriptionRequest):
    if WHISPER_MODEL is None:
        raise HTTPException(status_code=503, detail="Ø®Ø¯Ù…Ø© Whisper ØºÙŠØ± Ù…ØªØ§Ø­Ø© Ø£Ùˆ Ù‚ÙŠØ¯ Ø§Ù„ØªØ­Ù…ÙŠÙ„.")
        
    log(f"Ø¨Ø¯Ø¡ ØªÙØ±ÙŠØº: {req.audio_url}")
    
    # 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ù…Ù† URL (Ù…Ù‡Ù… Ù„Ù„Ø±Ø¨Ø· Ø¨Ù€ MinIO/S3)
    try:
        response = requests.get(req.audio_url, stream=True, timeout=10)
        response.raise_for_status()
        
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ù…Ø¤Ù‚ØªØ§Ù‹ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© (Ù„ØªÙ„Ø¨ÙŠØ© Ù…ØªØ·Ù„Ø¨Ø§Øª Faster Whisper Ùˆ PyAnnote)
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
            for chunk in response.iter_content(chunk_size=8192):
                tmp_file.write(chunk)
            audio_path = tmp_file.name
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„ØµÙˆØª Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±: {e}")

    # 2. Ø§Ù„ØªÙØ±ÙŠØº Ø§Ù„ØµÙˆØªÙŠ (Transcription)
    try:
        segments, _ = WHISPER_MODEL.transcribe(audio_path, beam_size=5, language=req.language)
        transcription = "".join(segment.text for segment in segments)
    except Exception as e:
        os.unlink(audio_path)
        raise HTTPException(status_code=500, detail=f"ÙØ´Ù„ Ø§Ù„ØªÙØ±ÙŠØº Ø§Ù„ØµÙˆØªÙŠ: {e}")

    # 3. ØªÙ…ÙŠÙŠØ² Ø§Ù„Ù…ØªØ­Ø¯Ø«ÙŠÙ† (Diarization)
    diarization_result = None
    if DIARIZATION_PIPELINE:
        try:
            diarization_raw = DIARIZATION_PIPELINE(audio_path)
            diarization_result = [
                {"speaker": turn.speaker, "start": turn.start, "end": turn.end}
                for turn in diarization_raw.itertracks(yield_label=True)
            ]
        except Exception as e:
            log(f"ðŸŸ¡ ÙØ´Ù„ ØªÙ…ÙŠÙŠØ² Ø§Ù„Ù…ØªØ­Ø¯Ø«ÙŠÙ†: {e}")
            
    os.unlink(audio_path) # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
    
    return {
        "status": "success",
        "full_text": transcription,
        "speaker_diarization": diarization_result if diarization_result else "Diariaztion Failed/Disabled"
    }

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8080)
PYTHON_ASR

# -----------------------------------------------------
# 4. Ø¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¡ Ø§Ù„ØµÙˆØ±Ø©
# -----------------------------------------------------
log "4/4. Ø¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¡ ØµÙˆØ±Ø© ASR Engine (Ù„Ø§ÙƒØªØ³Ø§Ø¨ FFmpeg ÙˆØ§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©)..."

# Ù†Ø³ØªØ®Ø¯Ù… sed Ù„Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ Entrypoint Ù‚Ø¯ÙŠÙ… Ù‚Ø¯ ÙŠØ¹ÙŠÙ‚ Ø¹Ù…Ù„ Dockerfile Ø§Ù„Ø¬Ø¯ÙŠØ¯
sed -i '/ENTRYPOINT/d' "$APP_DIR/Dockerfile" || true 

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨Ù†Ø§Ø¡
docker compose build --no-cache asr-engine || die "ðŸ”´ ÙØ´Ù„ Ø¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¡ ØµÙˆØ±Ø© ASR Engine."

log "âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« ASR Engine Ø¨Ø§Ù„ÙƒØ§Ù…Ù„. ÙŠØ±Ø¬Ù‰ ØªØ²ÙˆÙŠØ¯ HUGGINGFACE_TOKEN ÙÙŠ Compose."
