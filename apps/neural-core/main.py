from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline
import torch
import os

app = FastAPI(title="Neural Core - Multi-Dialect NLP Engine")

# FFIX: ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¹Ø§Ù„Ù…ÙŠØ§Ù‹
ARABERT_NER_PIPELINE = None
MBERT_NER_PIPELINE = None # Ù„Ù„ØºØ§Øª Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø© ÙˆØ§Ù„Ø£Ù…Ø§Ø²ÙŠØºÙŠØ©

class AnalysisRequest(BaseModel):
    text: str 
    lang_model: str = "ar" # 'ar' for Arabic/Dialects, 'multi' for Tamazight/Multilingual

app = FastAPI(title="Neural Core - Multi-Dialect NLP Engine")

def log(msg):
    print(f"[NLP Core] {msg}", flush=True)

@app.on_event("startup")
async def startup_event():
    global ARABERT_NER_PIPELINE, MBERT_NER_PIPELINE
    log("Ø¨Ø¯Ø¡ ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ NLP...")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # 1. ØªØ­Ù…ÙŠÙ„ AraBERT (Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ ÙˆØ§Ù„Ø¯Ø§Ø±Ø¬Ø© Ø§Ù„Ù…ØºØ±Ø¨ÙŠØ©/Ø§Ù„Ù…Ø´Ø±Ù‚ÙŠØ©)
    try:
        log("ğŸŸ¢ ØªØ­Ù…ÙŠÙ„ AraBERT NER (Ù„Ù„Ø¯Ø§Ø±Ø¬Ø©/Ø§Ù„ÙØµØ­Ù‰).")
        # Ù†Ù…ÙˆØ°Ø¬ NER Ù…Ø¯Ø±Ø¨ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ø¹Ø±Ø¨ÙŠ Ù…ØªÙ†ÙˆØ¹
        model_name = "CAMeL-Lab/bert-base-arabic-camel-msa-ner"
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForTokenClassification.from_pretrained(model_name).to(device)
        ARABERT_NER_PIPELINE = pipeline(
            "ner", model=model, tokenizer=tokenizer, device=0 if device.type == "cuda" else -1
        )
    except Exception as e:
        log(f"ğŸ”´ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ AraBERT: {e}")

    # 2. ØªØ­Ù…ÙŠÙ„ MBERT (Ù„Ù„ØºØ§Øª Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø© ÙˆØ§Ù„Ø£Ù…Ø§Ø²ÙŠØºÙŠØ©)
    try:
        log("ğŸŸ¡ ØªØ­Ù…ÙŠÙ„ MBERT (Ù„Ù„ØªØºØ·ÙŠØ© Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©/Ø§Ù„Ø£Ù…Ø§Ø²ÙŠØºÙŠØ©).")
        # Ù†Ù…ÙˆØ°Ø¬ Multilingual BERT (ÙŠØºØ·ÙŠ 104 Ù„ØºØ§ØªØŒ Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ Ø§Ù„Ù„Ø§ØªÙŠÙ†ÙŠØ© ÙˆØ§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)
        model_name = "bert-base-multilingual-cased"
        tokenizer_m = AutoTokenizer.from_pretrained(model_name)
        model_m = AutoModelForTokenClassification.from_pretrained('davidsbatista/mdeberta-v3-base-ner-wikiann').to(device)
        MBERT_NER_PIPELINE = pipeline(
            "ner", model=model_m, tokenizer=tokenizer_m, device=0 if device.type == "cuda" else -1, aggregation_strategy="simple"
        )
    except Exception as e:
        log(f"ğŸ”´ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ MBERT: {e}")


@app.get("/health")
async def health():
    return {
        "status": "healthy",
        "service": "neural-core",
        "ar_status": "READY" if ARABERT_NER_PIPELINE else "FAILED/PENDING",
        "multi_status": "READY" if MBERT_NER_PIPELINE else "FAILED/PENDING"
    }

@app.post("/analyze/ner")
async def analyze_ner(req: AnalysisRequest):
    pipeline_to_use = None
    
    if req.lang_model == 'ar' and ARABERT_NER_PIPELINE:
        pipeline_to_use = ARABERT_NER_PIPELINE
        model_info = "AraBERT NER (Arabic/Dialects)"
    elif req.lang_model == 'multi' and MBERT_NER_PIPELINE:
        pipeline_to_use = MBERT_NER_PIPELINE
        model_info = "MBERT NER (Multilingual/Tamazight)"
    else:
        raise HTTPException(status_code=503, detail=f"Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {req.lang_model} ØºÙŠØ± Ù…ØªØ§Ø­ Ø£Ùˆ Ù‚ÙŠØ¯ Ø§Ù„ØªØ­Ù…ÙŠÙ„. Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¹Ø±Ø¨ÙŠ: {ARABERT_NER_PIPELINE is not None}, Ø­Ø§Ù„Ø© Ø§Ù„Ù…ØªØ¹Ø¯Ø¯: {MBERT_NER_PIPELINE is not None}")

    try:
        # ØªÙ†ÙÙŠØ° Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³Ù…Ø§Ø© (NER)
        results = pipeline_to_use(req.text)
        
        # ØªØµÙÙŠØ© ÙˆØ¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        return {
            "status": "success",
            "model": model_info,
            "entities": results
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù„ØºÙˆÙŠ: {e}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
